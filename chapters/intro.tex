\chapter{Introduction}
\section{Computer Simulations}
Computer simulation is the discipline of designing a model of an actual or 
theoretical system, executing the model on a digital computer, and 
analyzing the execution output. Computer simulations have become a useful part of mathematical modeling of 
many natural systems in various disciplines of science. 

In science, typically two types of computer simulations are used. First is a 
numerical simulation of differential equations that cannot be solved 
analytically. In the recent discovery of gravitational waves from a binary
black hole merger, LIGO scientists used numerical simulations to provide 
estimates of the mass and spin of the final black hole, the total energy 
radiated in gravitational waves, and the peak gravitational-wave luminosity.
They were also able to verify that their observation is consistent with general 
relativity.

Another type is the stochastic simulation. A stochastic simulation is a 
simulation that traces the evolution of variables that can change stochastically
 (randomly) with certain probabilities. With a stochastic model we create a 
projection which is based on a set of  random values. 
Outputs are recorded and the projection is repeated with a new 
set of random values of the variables. These steps are repeated until a 
sufficient amount of data is gathered. In the end, the distribution of the 
outputs shows the most probable estimates as well as a frame of expectations 
regarding what ranges of values the variables are more or less likely to fall 
in. 

One of the most widely used stochastic simulation methods is the Monte Carlo
methods. Named after the famous casino in Monaco, Monte Carlo methods use
repeated random sampling to obtain numerical results. By the law of large 
numbers, the average of the results obtained from a large number of trials
should be close the the expected value, and gets closer as more test trials
are performed. Therefore, an integral can be evaluated by randomly sampling
the phase space and sum over the samples. 
In physics, Monte Carlo methods are very useful for complex systems such as 
disordered systems, strongly coupled systems, etc. 

\section{Disordered Systems}
In physics, the terms order and disorder designate the presence or absence of 
some symmetry or correlation in a many-particle system. 
The disorder can be put into two main categories according to their dynamics: 
annealed disorder and quenched disorder.

In statistical physics, a system is said to present quenched disorder when 
some parameters defining its behavior are random variables which do not evolve 
with time. Spin glasses are a classical example of quenched disorder.

A system is said to present annealed disorder when some parameters entering 
its definition are random variables, but whose evolution is related to that 
of the degrees of freedom defining the system.

Define what kind of disorder in real systems. They are most from dilution or 
doping, giving examples. 

\section{Strongly Correlated Systems}
Strongly correlated materials are a wide class of compounds containing ions 
with d- or f-orbitals, that show unusual electronic and magnetic properties. 
They include insulators, magnets, paramagnets and superconductors.

\section{Heterogeneous Computing}
%intro
Heterogeneous computing refers to systems that use more than one kind of 
processor or cores. These system gain performance and efficiency by adding
different processors/accelerators, and divide the task among them to utilize 
their specialized capabilities. 
Popular examples of such accelerators, according to this definition, include 
GPUs, FPGAs, Intel Xeon Phi coprocessors, etc.

%Hardwares
%FPGA?

Graphic processing units, or GPUs, are typically used in computers for image 
processing. 
Due to the performance, it is becoming increasingly common to use a general purpose 
graphics processing unit (GPGPU).
A CPU consists of a few cores optimized for sequential serial processing,
while a GPU has a massively parallel architecture 
consisting of thousands of small cores designed for handling multiple tasks 
simultaneously.
For example, a Nvidia K80 GPU has 2496 cores, and can achieve up to 2.91 TFlops 
double precision performance and up to 8.74 TFlops single precision performance, 
and has a bandwidth of 480GB/s.
The dominant framework in GPU programming is Nvidia CUDA, which allows 
programmers to write codes with C, C++ and Fortran and run the program on CUDA
enabled GPUs.


Intel Xeon Phi is a coprocessor developed by Intel that features a 
X86-compatible architecture. With up to 61 cores, 244 threads, 
and 1.2 teraFLOPS of performance, a Xeon Phi delivers up to 2.3 times higher 
peak FLOPS than Intel Xeon processor E5 family-based servers.
Since languages, tools, and applications are compatible for both Intel Xeon 
processor and Intel Xeon Phi coprocessors, it is easier for programmers to
design, write, compile and optimize their code. 


%Pros and Cons when speeding up code within heterogeneous systems.

%Pros:
% performance

Heterogeneous systems are capable of delivering better performance than 
traditional homogeneous systems, by exploits the diversity offered by different 
processors/instruction set architectures(ISAs). 
%http://www.nvidia.com/object/why-choose-tesla.html#sthash.s2ypSuA2.dpuf
The huge performance increase over CPUs make accelerators popular choices for
supercomputers. Tianhe-2, a supercomputer developed by Chinaâ€™s National 
University of Defense Technology, leads the list of top 500 supercomputers.
It utilizes 48,000  Intel Xeon Phi coprocessors and 32,000 Ivy Bridge-EP Xeon 
processors to achieve 33.86 petaFLOPS.

% energy efficiency
Heterogeneous systems also have much better energy efficiency. 
The power usage as well as the cooling cost required to support the computers
are now the primary cost of ownership for HPC data centers. Therefore,
the HPC community now understands that supercomputers should not be evaluated
solely on the basis of speed, but should also consider metrics related to 
energy efficiency. The most popular metric is the FLOPS/watt.
%[http://www.green500.org/docs/pubs/hp-pac2006.pdf]
By using energy-efficient accelerators,
heterogeneous systems can significantly reduce the energy-footprint. 
In fact, heterogeneous accelerator-based systems have been dominating the 
top places of the Green500, %[www.green500.org]
a ranking of the most energy-efficient supercomputers in the world. 
In the November 2015 edition of the list, 
the top 40 supercomputers listed all used accelerators of one form or another.

%Cons:
% Complexity in programming, utilization,
Albeit the advantages in the hardware, the heterogeneous nature present new
and unique challenges for programmers and scientists. 

%Parallelism
In parallel programming, programmers need to explore the problem for 
possibility of parallelization, map the tasks onto threads, schedule for
communication and/or synchronization, and solve problems such as race conditions,
etc. Communication and barriers could result in parallel slow-down, 
a situation in which the overhead from communication outweighs the performance 
gain from parallelism, and further parallelization increases the time to finish
the workload. 
Accelerators use a huge number of cores to achieve great performance. 
To utilize all the cores, a lot of parallelism is required, and efficient 
parallelism is critical.

%memory architecture
Different processors/accelerators often feature different memory architecture.
To achieve the best possible performance, architecture aware memory access is 
very important to utilize the high memory bandwidth and reduce the latency.
This is even more important in programming for accelerators such as GPUs than in
CPU programming, since the latency is not hidden by large cache.
For example, in CUDA %, the architecture Nvidia use for programming their GPUs, 
there are different types of memory such as registers, local memory, shared 
memory, global memory, and constant memory, etc. Each of these types are 
different in terms of size, latency, bandwidth, and performance profile for 
various access modes, and one have to make conscious decisions when using them
in order to avoid performance penalties and make the best of the hardware. 
In CUDA, this means programmers need to put the correct qualifiers in front when 
declaring their variables, and move their variables around the memory hierarchy 
when needed.
 
%Communication
%Since the accelerators are usually connected to the CPU via the PCI express bus,their communication bandwidth with the CPU are limited.
%CPU-accelerator communication
%Inter-accelerator communication

% Portability, compilers and tools
The different architecture of processors makes it hard to write portable codes.

%Programming models

\section{Scope and Structure}


\iffalse
Spin glass \cite{Binder-Young1986} are magnetic systems where the frozen-in 
structural disorder leads to conflicting magnetic moments, which prevents the
formation of long range magnetic ordering, e.g., ferromagnetic ordering.

The prototype material is a dilute magnetic alloy, with a small amount of 
magnetic impurity (such as Fe, Mn) randomly substituted into the lattice of a 
noble metallic host (i.e. Cu, Au). The conduction electron-mediated 
Ruderman-Kittel-Kasuya-Yoshida (RKKY) interactions between the localized moments
 oscillates strongly with distance, thus forming ferromagnetic/anti 
ferromagnetic bonds randomly, and no spin alignment would satisfactory all 
exchange bonds. 

Experiments demonstrated some unusual features of spin glass materials, 
including the cusp in the low-field, low-frequency susceptibility and the 
discrepancy of magnetic response between zero-field and field cooling 
measurements. These facts suggest that spin glass system has no conventional 
long range magnetic ordering and exhibits very slow dynamics. 

The simplest model that captures the consequences of disorder is an Ising model 
with quenched randomly disordered couplings. This model was first proposed by 
Edwards and Anderson (EA). \cite{Edwards-Anderson1975} The mean field solution 
of the EA model for infinite dimensions was first attempted by Sherrington and 
Kirkpatrick. \cite{Sherrington-Kirkpatrick1978} However, the replica symmetric 
mean field solution was found to be unstable below the Almeida-Thouless line, 
\cite{Almedia-Thouless1978,Bray-Moore-1978} a line in the temperature-field 
plane below which replica symmetry is broken. The difficulty of obtaining a 
stable solution was solved by Parisi with his replica symmetry breaking ansatz. 
%\cite{Parisi-1979,Mezard-etal-1984,Parisi-1980a,Parisi-1980b,Parisi-1980c,
%Parisi-dirac-medal-2002} 
\cite{Parisi1980}.
Although the mean field solution has been proven to 
provide the exact free energy for the spin glass phase in infinite dimensions, 
\cite{Talagrand-2006,Guerra-2003} the spin glass physics in finite dimensions, 
which presumably is more relevant to experiments, is still not fully understood.
 Indeed, it had long been debated whether a spin glass 
phase at finite temperatures exists in three dimensions.

The EA model is a deceptively simple problem. %Since it is a classical spin 
%model, one may think that its numerical study can be simply carried out by Monte
%Carlo methods on conventional hardware. 
One of the defining signatures of spin glass systems is their long relaxation 
time. 
For sufficiently low temperatures, the system becomes very sluggish and 
equilibration is prohibitively difficult even for modest systems sizes. 
Moreover, it has been shown that finding the ground state of the three 
dimensional EA model is an NP-hard problem. \cite{Barahona-1982} 
Until recently, there has been no consensus on whether there is a finite spin 
glass critical temperature in the three dimensional EA model.

The breakthrough in the numerical study of spin glass systems came with the 
introduction of the parallel tempering method. It allowed the study of larger 
systems at lower temperatures than the simple single spin flip %Monte Carlo 
method. \cite{Swendsen-Wang-1986,Hukushima-Nemoto1996,Marinari-Parisi1992} 
Combined with improved schemes for finite size scaling, it is now widely 
believed that the thermodynamic finite-temperature spin glass phase does exist 
in the three dimensional EA model~\cite{Ballesteros2000}. As the upper critical 
dimension of the model is six \cite{Harris-Lubensky-Chen-1976,Tasaki-1989,
Green-Moore-Bray-1983}, a prominent remaining question is the nature of the 
spin glass phase below the upper critical dimension~\cite{Young-Katzgraber2004}.
In particular, if the spin glass can still be described by the replica symmetry 
breaking scenario, there should be an Almeida-Thouless line below the upper 
critical dimension. A possible test of whether the Almeida-Thouless 
line exists is to determine whether a spin glass phase exists under an external 
magnetic field. Correlation length scaling analysis seems to suggest the 
absence of the spin glass phase in cubic lattices when a finite external field 
is applied.\cite{Young-Katzgraber2004} On the other hand, a recent study in 
four-dimensional lattices suggests that by using a different quantity for the 
finite size scaling analysis, a spin glass phase can be revealed.
\cite{Banos2012} Given the relevance of spin glasses and the on-going 
controversy on the nature of the spin glass phase below the upper critical 
dimension, it is desirable to implement an efficient parallel tempering Monte 
Carlo algorithm using graphics processing units to accelerate the simulations. 
In this work we show that using the multispin coding method, 
\cite{Zorn1981337} an efficient Monte Carlo algorithm can be 
implemented on the GPU. We will demonstrate that graphic card computing is 
particularly well suited for equilibrium simulations of spin glass systems, 
in particular for cases where a huge number of realizations is required such as 
the model we study in this work. 

%insert intro to CTHYB and Dynamic Hubbard model here
Numerical calculation in strongly correlated fermion systems is another major 
challenge in condensed matter physics. In real world, materials consists of 
$10^{23}$ interacting particles, which is impossible to solve at first glance. 
Fortunately, not all the particles contribute to the property of materials. For 
example, In a metal only the electrons close to the Fermi level can be excited 
and contribute ,e.g., to the transport and magnetic properties. In a lattice, 
lattice excitations are few at low T, but they are responsible for inelastic 
neutron scattering. Even though, the remaining problem is still hard. 

Density functional theory (DFT)\cite{PhysRev.136.B864,PhysRev.140.A1133} 
provides a framework to solve the 
electron structure problem. Using this theory, the properties of a many-electron
system can be described by a functional of election density. Combined with 
approximations that address the exchange-correlations such as the local density 
approximation (LDA) \cite{lundqvist1983}, DFT produces satisfactory data that agrees well the 
experiments for many cases. However, despite the success in weakly correlated 
materials, there are still difficulties in applying this method to other 
cases, such as systems with strongly correlation \cite{0953-8984-9-35-010}. 
It seems to be quite
difficult to handle such strong correlation by simple improvements of the 
DFT. A promising direction is to combine other methods which can treat
strong correlation with the DFT method. A popular choice is to employ 
the dynamical mean field theory\citep{RevModPhys.68.13,PhysRevB.45.6479} 
to include the effect from the electron-electron
correlation on top of the single particle dispersion obtained from the DFT. 

%DFT, ab inito

%maybe mention other numerical methods here?

DMFT has been widely studied on a range of strongly correlated systems. 
It is a method well suited for strongly correlated systems, in particular it 
captures the Mott transition, a hallmark of strong correlation, of the Hubbard 
model. In this approach, the solution of the lattice model is mapped to a 
quantum impurity model with self-consistency conditions. 
%intro to impurity
%mention other impurity solvers
A quantum impurity problem describes an atom embedded in a host medium. 
The impurity consists of a set of orbitals with different parameters, populated
with electrons that interacts with each other. The orbitals are hybridized to 
bath orbitals representing the degrees of freedom of the host materials. 
The solution of impurity problem can be obtained in a few different ways. 
We will focus on the different variants of Monte Carlo methods.

A commonly used technique is the Hirsch-Fye method \cite{1986PhRvL..56.2521H}, in which a 
Hubbard-Stratonovich transformation is used to decouple the interaction part,
leading to determinants which give the weights associated with the 
configurations of the auxiliary fields, which are then sampled by a Monte Carlo 
procedure. One issue is that Hirsch-Fye cannot be easily applied to complicated
interaction that include more than just density-density interaction, due to the
lack of simple ansatz to decouple the interacting terms. 
The matrix size scales to the interaction as well as the inverse of 
temperature, which makes the calculation inefficient at low temperatures.
This methods also requires discretization of the imaginary time interval,
which introduce systematic errors, and may not be optimal for multi-orbital case 
with complicated off-diagonal couplings.

The Trotter error in Hirsch-Fye algorithm can be eliminated by using the 
Continuous Time Monte Carlo algorithms. For example, one can solve the problem 
exactly in non-interacting limit, and treat the interaction with a Taylor-series
 expansion. By doing stochastic sampling of diagrams in the weak-coupling 
expansion of partition function, the interaction expansion (CT-INT) algorithm
\cite{2005PhRvB..72c5122R}
provides a discretization error free alternative Hirsch-Fye algorithm.
Still, in the CT-INT algorithm, it is difficult to treat non-Hubbard-type 
interactions. Also the size of the matrix used in the CT-INT method grows
quickly with the interaction, making the calculation very time-consuming at 
very strong interactions.

Another way to treat the impurity problem is the hybridization expansion (CT-HYB)
approach \cite{RevModPhys.83.349, PhysRevB.75.155113, PhysRevB.80.235117,
PhysRevB.74.155107}. 
The fact that the order of expansion decreases with increasing 
interaction makes this method favorable for strong interaction systems. 
The algorithm is also found to work at very low temperatures, and is applicable
to a wider class of impurity models including those with complicated 
off-diagonal couplings, since the local problem is treated exactly. 

%idea of cthyb, some advantage?
%intro to dynamical Hubbard model
One of the possible application of this CT-HYB algorithm is the Dynamic Hubbard
Models \cite{PhysRevLett.87.206402,2013PhyS...88c5704H}. Comparing to the conventional Hubbard model, Dynamic Hubbard Model 
describes the modification of the local interaction when two electrons 
occupy the same atomic orbital. It is expected that the Dynamic Hubbard Models
describe the asymmetry between the electron and hole carriers in metals, and can
be used to study the theory of hole superconductivity.
%do I need more on hole superconductivity? KM: No

%


The paper is organized as follows: 
We first discuss the study of Edwards-Anderson spin glass model in 
section~\ref{sec:EA}. 
The general algorithm is introduced in \ref{ssec:ea-alg}. 
The quantities we measured are introduced in the \ref{ssec:ea-measure}. 
In \ref{ssec:ea-implementation}, we show the detail of our implementation and 
optimization.  We conclude this part with our results in \ref{ssec:ea-result} 
and discuss the possible directions for the future study in \ref{ssec:ea-concl}.

In the next section, we discuss the hybridization expansion quantum impurity 
solver (CTHYB) and its application on Dynamic Hubbard Models. 
The algorithm of CTHYB is introduced in \ref{ssec:hyb-alg}, 
and the implementation methods is discussed in \ref{ssec:hyb-implementation}. 
%We briefly discuss the Dynamic Hubbard Models in \ref{ssec:hyb-mod}. 
We conclude this part with the advantages of this algorithm and possible 
applications in \ref{ssec:hyb-concl}.

\fi

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../thesis"
%%% End:
